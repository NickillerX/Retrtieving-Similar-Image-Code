{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyMezddAyCcK3dVJIEvFFHiL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Code to connect to gcs\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","!gcloud init"],"metadata":{"id":"3X64wshpztaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code to connect to google drive and to downlaod dataset from gcs\n","import os\n","from google.colab import drive\n","from google.cloud import storage\n","import subprocess\n","\n","# ---------- Configuration ----------\n","GCS_BUCKET = \"similar_dataset\"\n","GCS_DATASET_PATH = \"cnn_set\"\n","LOCAL_DATASET_PATH = \"/content/cnn_set\"\n","OUTPUT_DIRS = [\n","    \"/content/drive/MyDrive/ImageRetrievalProject/features\",\n","    \"/content/drive/MyDrive/ImageRetrievalProject/tsne_plots\",\n","    \"/content/drive/MyDrive/ImageRetrievalProject/stats\"\n","]\n","\n","# ---------- Functions ----------\n","def mount_drive():\n","    \"\"\"Mount Google Drive if not already mounted.\"\"\"\n","    try:\n","        drive.mount('/content/drive', force_remount=True)\n","        print(\"Google Drive mounted successfully.\")\n","    except Exception as e:\n","        print(f\"Google Drive mount failed: {e}\")\n","\n","def download_dataset_from_gcs(bucket_name, gcs_path, local_path):\n","    if os.path.exists(local_path):\n","        print(f\" Dataset already exists at {local_path}. Skipping download.\")\n","        return\n","    print(f\"⬇ Downloading dataset from gs://{bucket_name}/{gcs_path} to {local_path}...\")\n","    try:\n","        target_parent_dir = os.path.dirname(local_path) if os.path.dirname(local_path) else '/content/'\n","        command = f\"gsutil -m cp -r gs://{bucket_name}/{gcs_path} {target_parent_dir}\"\n","        subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n","        print(\"  Dataset downloaded successfully.\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\" Error downloading dataset: {e.stderr}\")\n","        exit()\n","\n","\n","def ensure_dirs(paths):\n","    \"\"\"Create directories if they do not exist.\"\"\"\n","    for path in paths:\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","            print(f\"Created directory: {path}\")\n","\n","# ---------- Execution ----------\n","if __name__ == '__main__':\n","    print(\"🔹 Starting Drive & Dataset Setup...\")\n","    mount_drive()\n","    download_dataset_from_gcs(GCS_BUCKET, GCS_DATASET_PATH, LOCAL_DATASET_PATH)\n","    ensure_dirs(OUTPUT_DIRS)\n","    print(\"Drive & dataset setup complete. Ready for feature extraction and retrieval.\")\n"],"metadata":{"id":"ncLeCvSEtWF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========================================\n","#       Feature Extraction (All Models)\n","# ========================================\n","\n","import os\n","import torch\n","import pickle\n","from torch import nn\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","\n","# -------- Configuration --------\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","BATCH_SIZE = 64\n","IMAGE_SIZE = (224, 224)\n","NUM_CLASSES = 20\n","DATASET_PATH = \"/content/cnn_set\"\n","FEATURE_SAVE_DIR = \"/content/drive/MyDrive/ImageRetrievalProject/features\"\n","os.makedirs(FEATURE_SAVE_DIR, exist_ok=True)\n","\n","# -------- Model Weights Paths --------\n","WEIGHTS = {\n","    \"customcnn\": \"/content/drive/MyDrive/ImageRetrievalProject/metrics/customcnn_35epoch/best_model.pth\",\n","    \"resnet50\": \"/content/drive/MyDrive/metrics/resnet50/best_model.pth\",\n","    \"efficientnet_b0\": \"/content/drive/MyDrive/metrics/efficientnet_b0/best_model.pth\",\n","    \"vgg16\": \"/content/drive/MyDrive/metrics/vgg16/best_model.pth\"\n","}\n","\n","# -------- Image Transforms --------\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(IMAGE_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std),\n","])\n","\n","# -------- Datasets & Dataloaders --------\n","# Use a custom dataset to get image paths directly\n","class ImagePathDataset(datasets.ImageFolder):\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        img = self.loader(path)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, target, path\n","\n","train_dataset = ImagePathDataset(os.path.join(DATASET_PATH, \"train\"), transform=transform)\n","val_dataset = ImagePathDataset(os.path.join(DATASET_PATH, \"val\"), transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# ========================================\n","#       Custom CNN Definition\n","# ========================================\n","class CustomCNN(nn.Module):\n","    def __init__(self, num_classes=NUM_CLASSES):\n","        super(CustomCNN, self).__init__()\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(3, 16, 3, 1, 1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2,2)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(16, 64, 3,1,1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2,2)\n","        )\n","        self.conv_block3 = nn.Sequential(\n","            nn.Conv2d(64, 256, 3,1,1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2,2)\n","        )\n","        self.conv_block4 = nn.Sequential(\n","            nn.Conv2d(256, 1024, 3,1,1), nn.BatchNorm2d(1024), nn.ReLU(), nn.MaxPool2d(2,2)\n","        )\n","        dummy = torch.zeros(1,3,224,224)\n","        out = self.conv_block1(dummy)\n","        out = self.conv_block2(out)\n","        out = self.conv_block3(out)\n","        out = self.conv_block4(out)\n","        self.flatten_dim = out.view(1,-1).shape[1]\n","        self.fc1 = nn.Linear(self.flatten_dim, 1024)\n","        self.fc2 = nn.Linear(1024,512)\n","        self.fc3 = nn.Linear(512,128)\n","        self.fc_out = nn.Linear(128, num_classes)\n","        self.dropout = nn.Dropout(0.15)\n","\n","    def forward(self, x):\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","        x = self.conv_block3(x)\n","        x = self.conv_block4(x)\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.fc3(x))\n","        return self.fc_out(x)\n","\n","# ========================================\n","#       Feature Extraction Function\n","# ========================================\n","def extract_features(model, loader, model_name):\n","    \"\"\"\n","    Dynamically extracts features, labels, and paths.\n","    \"\"\"\n","    model.eval()\n","    model = model.to(DEVICE)\n","    features, labels, paths = [], [], []\n","\n","    with torch.no_grad():\n","        for inputs, targets, img_paths in tqdm(loader, desc=f\"Extracting {model_name} features\"):\n","            inputs = inputs.to(DEVICE)\n","\n","            if model_name == \"customcnn\":\n","                # Manual forward pass for CustomCNN to get the feature vector\n","                x = model.conv_block1(inputs)\n","                x = model.conv_block2(x)\n","                x = model.conv_block3(x)\n","                x = model.conv_block4(x)\n","                x = x.view(x.size(0), -1)\n","                x = F.relu(model.fc1(x))\n","                x = F.relu(model.fc2(x))\n","                x = model.dropout(x)\n","                out = F.relu(model.fc3(x))\n","            elif model_name == \"vgg16\":\n","                # Manual forward pass for VGG16 to handle the avgpool layer correctly\n","                x = model.features(inputs)\n","                x = model.avgpool(x)\n","                x = torch.flatten(x, 1)\n","                x = model.classifier[0](x)\n","                x = F.relu(x)\n","                x = model.classifier[1](x)\n","                x = F.relu(x)\n","                x = model.classifier[2](x)\n","                out = F.relu(x) # This is the feature vector (4096 dim)\n","            else:\n","                out = model(inputs)\n","\n","            out_flat = out.view(out.size(0), -1)\n","            features.extend(out_flat.cpu().numpy())\n","            labels.extend(targets.cpu().numpy())\n","            paths.extend(img_paths)\n","\n","    return features, labels, paths\n","\n","# ========================================\n","#       Model Loading & Feature Extraction\n","# ========================================\n","def process_model(model_name, model, loader_train, loader_val, weight_path=None):\n","    # Load weights for the full model\n","    if weight_path is not None and os.path.exists(weight_path):\n","        model.load_state_dict(torch.load(weight_path, map_location=DEVICE))\n","        print(f\"{model_name} weights loaded from {weight_path}\")\n","\n","    # Create the feature extraction model by removing the final classification layer\n","    if model_name == \"customcnn\" or model_name == \"vgg16\":\n","        feature_model = model # Use the full model and handle feature extraction in the loop\n","    elif model_name == \"resnet50\":\n","        feature_model = nn.Sequential(*list(model.children())[:-1])\n","    elif model_name == \"efficientnet_b0\":\n","        feature_model = nn.Sequential(model.features, model.avgpool, model.classifier[0])\n","    else:\n","        raise ValueError(\"Model type not supported for feature extraction.\")\n","\n","    # Extract train + val features\n","    print(f\"Extracting features for {model_name} - TRAIN\")\n","    train_features, train_labels, train_paths = extract_features(feature_model, loader_train, model_name)\n","    print(f\"Extracting features for {model_name} - VAL\")\n","    val_features, val_labels, val_paths = extract_features(feature_model, loader_val, model_name)\n","\n","    # Merge train + val\n","    all_features = train_features + val_features\n","    all_labels = train_labels + val_labels\n","    all_paths = train_paths + val_paths\n","\n","    # Save to .pkl\n","    save_path = os.path.join(FEATURE_SAVE_DIR, f\"{model_name}_features.pkl\")\n","    with open(save_path, 'wb') as f:\n","        pickle.dump({'features': all_features, 'labels': all_labels, 'paths': all_paths}, f)\n","    print(f\"Saved merged features for {model_name} at {save_path}\")\n","\n","# ========================================\n","#       Execute All Models\n","# ========================================\n","def main():\n","    # 1️ Custom CNN\n","     #custom_cnn = CustomCNN()\n","     #process_model(\"customcnn\", custom_cnn, train_loader, val_loader,\n","               #    weight_path=WEIGHTS[\"customcnn\"])\n","\n","    # 2️ ResNet50\n","     #resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n","     #resnet.fc = nn.Linear(resnet.fc.in_features, NUM_CLASSES)\n","    # process_model(\"resnet50\", resnet, train_loader, val_loader,\n","                #   weight_path=WEIGHTS[\"resnet50\"])\n","\n","    # 3️ EfficientNet-B0\n","   #  efficient = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n","    # efficient.classifier[1] = nn.Linear(efficient.classifier[1].in_features, NUM_CLASSES)\n","    # process_model(\"efficientnet_b0\", efficient, train_loader, val_loader,\n","                 #  weight_path=WEIGHTS[\"efficientnet_b0\"])\n","\n","    # 4️ VGG16\n","    vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n","    vgg.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n","    process_model(\"vgg16\", vgg, train_loader, val_loader,\n","                  weight_path=WEIGHTS[\"vgg16\"])\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"0Kx9Rf7AF7aX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iZ_uBoO4q54d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===========================\n","# FULL CUSTOM CNN TRAINING SCRIPT V1\n","# ===========================\n","import os\n","import json\n","import time\n","import copy\n","import subprocess\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","\n","# ---- 1. GOOGLE DRIVE MOUNT ----\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    print(\" Google Drive mounted successfully.\")\n","except ImportError:\n","    print(\" Not running in Colab, skipping drive mount.\")\n","\n","# ---- 2. CONFIG ----\n","CNN_NAME = \"customcnn\"\n","NUM_EPOCHS = 35\n","BASE_METRICS_DIR = \"/content/drive/MyDrive/ImageRetrievalProject/metrics\"\n","RUN_METRICS_DIR = os.path.join(BASE_METRICS_DIR, f\"{CNN_NAME}_{NUM_EPOCHS}epoch\")\n","os.makedirs(RUN_METRICS_DIR, exist_ok=True)\n","\n","CONFIG = {\n","    \"batch_size\": 64,\n","    \"num_epochs\": NUM_EPOCHS,\n","    \"learning_rate\": 1e-5,\n","    \"weight_decay\": 1e-4,\n","    \"min_lr\": 1e-7,\n","    \"image_size\": (224, 224),\n","    \"best_model_path\": os.path.join(RUN_METRICS_DIR, \"mod_arch_best_model.pth\"),\n","    \"metrics_json\": os.path.join(RUN_METRICS_DIR, \"training_metrics.json\")\n","}\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","!gcloud init\n","\n","\n","# ---- 3. DOWNLOAD DATASET FROM GCS ----\n","GCS_BUCKET_NAME = 'similar_dataset'\n","GCS_DATASET_PATH = 'cnn_set'\n","LOCAL_DATA_ROOT = '/content/cnn_set'\n","\n","def download_dataset_from_gcs(bucket_name, gcs_path, local_path):\n","    if os.path.exists(local_path):\n","        print(f\" Dataset already exists at {local_path}. Skipping download.\")\n","        return\n","    print(f\"⬇ Downloading dataset from gs://{bucket_name}/{gcs_path} to {local_path}...\")\n","    try:\n","        target_parent_dir = os.path.dirname(local_path) if os.path.dirname(local_path) else '/content/'\n","        command = f\"gsutil -m cp -r gs://{bucket_name}/{gcs_path} {target_parent_dir}\"\n","        subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n","        print(\"  Dataset downloaded successfully.\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\" Error downloading dataset: {e.stderr}\")\n","        exit()\n","\n","download_dataset_from_gcs(GCS_BUCKET_NAME, GCS_DATASET_PATH, LOCAL_DATA_ROOT)\n","\n","\n","\n","\n","\n","\n","\n","# ---- 4. CNN ARCHITECTURE ----\n","class CNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN, self).__init__()\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(3, 16, 3, 1, 1),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(16, 64, 3, 1, 1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block3 = nn.Sequential(\n","            nn.Conv2d(64, 256, 3, 1, 1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block4 = nn.Sequential(\n","            nn.Conv2d(256, 1024, 3, 1, 1),\n","            nn.BatchNorm2d(1024),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","        dummy_input = torch.zeros(1, 3, 224, 224)\n","        with torch.no_grad():\n","            out = self.conv_block4(self.conv_block3(self.conv_block2(self.conv_block1(dummy_input))))\n","            self.flatten_dim = out.view(1, -1).size(1)\n","\n","        self.fc1 = nn.Linear(self.flatten_dim, 1024)\n","        self.fc2 = nn.Linear(1024, 512)\n","        self.fc3 = nn.Linear(512, 128)\n","        self.fc_out = nn.Linear(128, num_classes)\n","        self.dropout = nn.Dropout(0.15)\n","\n","    def forward(self, x):\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","        x = self.conv_block3(x)\n","        x = self.conv_block4(x)\n","        x = x.view(-1, self.flatten_dim)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.fc3(x))\n","        return self.fc_out(x)\n","\n","# ---- 5. DEVICE ----\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\" Using device: {DEVICE}\")\n","\n","# ---- 6. DATA ----\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(CONFIG[\"image_size\"], scale=(0.8, 1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize(CONFIG[\"image_size\"]),\n","    transforms.CenterCrop(CONFIG[\"image_size\"]),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_data = datasets.ImageFolder(os.path.join(LOCAL_DATA_ROOT, \"train\"), transform=train_transform)\n","val_data = datasets.ImageFolder(os.path.join(LOCAL_DATA_ROOT, \"val\"), transform=val_transform)\n","\n","train_loader = DataLoader(train_data, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_data, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=2, pin_memory=True)\n","\n","\n","\n","# ---- 7. MODEL/LOSS/OPTIMIZER ----\n","model = CNN(num_classes=len(train_data.classes)).to(DEVICE)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=CONFIG[\"min_lr\"])\n","\n","# ---- 8. TRAINING LOOP ----\n","train_losses, val_losses, train_accs, val_accs, epoch_times = [], [], [], [], []\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","\n","print(\" Starting training...\\n\")\n","total_start_time = time.time()\n","\n","for epoch in range(CONFIG[\"num_epochs\"]):\n","    epoch_start = time.time()\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","\n","    for batch_idx, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","        if (batch_idx + 1) % max(1, len(train_loader)//10) == 0:\n","            print(f\" Epoch [{epoch+1}/{CONFIG['num_epochs']}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n","\n","    avg_train_loss = running_loss / total\n","    train_acc = 100 * correct / total\n","\n","    # Validation\n","    model.eval()\n","    val_loss, val_correct, val_total = 0.0, 0, 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            val_correct += (preds == labels).sum().item()\n","            val_total += labels.size(0)\n","    avg_val_loss = val_loss / val_total\n","    val_acc = 100 * val_correct / val_total\n","\n","    train_losses.append(avg_train_loss)\n","    val_losses.append(avg_val_loss)\n","    train_accs.append(train_acc)\n","    val_accs.append(val_acc)\n","    scheduler.step(avg_val_loss)\n","    epoch_time = time.time() - epoch_start\n","    epoch_times.append(epoch_time)\n","    improved = avg_val_loss < best_val_loss\n","    if improved:\n","        best_val_loss = avg_val_loss\n","        epochs_no_improve = 0\n","        torch.save(model.state_dict(), CONFIG[\"best_model_path\"])\n","    else:\n","        epochs_no_improve += 1\n","    print(f\"\\n Epoch [{epoch+1}/{CONFIG['num_epochs']}] Summary:\")\n","    print(f\"   Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n","    print(f\"   Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}% {' IMPROVED' if improved else ' NO IMPROVEMENT'}\")\n","    print(f\"   Epoch Time: {epoch_time:.2f}s | ETA: ~{int(np.mean(epoch_times)*(CONFIG['num_epochs']-epoch-1))}s\")\n","    print(f\"  Patience: {epochs_no_improve}/3\\n\")\n","    if epochs_no_improve >= 3:\n","        print(\" Early stopping triggered. Loading best model...\")\n","        model.load_state_dict(torch.load(CONFIG[\"best_model_path\"]))\n","        break\n","\n","\n","\n","\n","\n","# ---- 9. SAVE METRICS ----\n","metrics = {\n","    \"train_loss\": train_losses,\n","    \"val_loss\": val_losses,\n","    \"train_acc\": train_accs,\n","    \"val_acc\": val_accs,\n","    \"epoch_times\": epoch_times\n","}\n","with open(CONFIG[\"metrics_json\"], \"w\") as f:\n","    json.dump(metrics, f, indent=4)\n","\n","print(f\" Metrics saved to {CONFIG['metrics_json']}\")\n","\n","# ---- 10. PLOT CURVES ----\n","plt.figure(figsize=(12,5))\n","plt.subplot(1,2,1)\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Val Loss')\n","plt.legend()\n","plt.title('Loss Curve')\n","\n","plt.subplot(1,2,2)\n","plt.plot(train_accs, label='Train Acc')\n","plt.plot(val_accs, label='Val Acc')\n","plt.legend()\n","plt.title('Accuracy Curve')\n","\n","plt.savefig(os.path.join(RUN_METRICS_DIR, \"training_curves.png\"))\n","plt.show()\n","\n","# ---- 11. CONFUSION MATRIX & REPORT ----\n","all_preds, all_labels = [], []\n","model.eval()\n","with torch.no_grad():\n","    for inputs, labels in val_loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","cm = confusion_matrix(all_labels, all_preds)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_data.classes)\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n","plt.title(\"Confusion Matrix\")\n","plt.savefig(os.path.join(RUN_METRICS_DIR, \"confusion_matrix.png\"))\n","plt.show()\n","\n","report = classification_report(all_labels, all_preds, target_names=train_data.classes)\n","with open(os.path.join(RUN_METRICS_DIR, \"classification_report.txt\"), \"w\") as f:\n","    f.write(report)\n","\n","print(\"\\nTraining complete! All metrics & plots saved.\")\n"],"metadata":{"id":"eVlpsWOS1hnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7QOKGdTbrNe7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===========================\n","# FINAL CUSTOM CNN TRAINING SCRIPT V2\n","# ===========================\n","import os\n","import json\n","import time\n","import copy\n","import subprocess\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","\n","# ---- 1. GOOGLE DRIVE MOUNT ----\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    print(\" Google Drive mounted successfully.\")\n","except ImportError:\n","    print(\" Not running in Colab, skipping drive mount.\")\n","\n","# ---- 2. CONFIG ----\n","CNN_NAME = \"customcnn_v2\"\n","NUM_EPOCHS = 50\n","BASE_METRICS_DIR = \"/content/drive/MyDrive/ImageRetrievalProject/metrics\"\n","RUN_METRICS_DIR = os.path.join(BASE_METRICS_DIR, f\"{CNN_NAME}_{NUM_EPOCHS}epoch\")\n","os.makedirs(RUN_METRICS_DIR, exist_ok=True)\n","\n","CONFIG = {\n","    \"batch_size\": 64,\n","    \"num_epochs\": NUM_EPOCHS,\n","    \"learning_rate\": 1.5e-4,\n","    \"weight_decay\": 5e-5,\n","    \"min_lr\": 1e-7,\n","    \"image_size\": (224, 224),\n","    \"best_model_path\": os.path.join(RUN_METRICS_DIR, \"best_model.pth\"),\n","    \"metrics_json\": os.path.join(RUN_METRICS_DIR, \"training_metrics.json\")\n","}\n","\n","# ---- 3. DOWNLOAD DATASET FROM GCS ----\n","GCS_BUCKET_NAME = 'similar_dataset'\n","GCS_DATASET_PATH = 'cnn_set'\n","LOCAL_DATA_ROOT = '/content/cnn_set'\n","\n","def download_dataset_from_gcs(bucket_name, gcs_path, local_path):\n","    if os.path.exists(local_path):\n","        print(f\" Dataset already exists at {local_path}. Skipping download.\")\n","        return\n","    print(f\"⬇ Downloading dataset from gs://{bucket_name}/{gcs_path} to {local_path}...\")\n","    try:\n","        target_parent_dir = os.path.dirname(local_path) if os.path.dirname(local_path) else '/content/'\n","        command = f\"gsutil -m cp -r gs://{bucket_name}/{gcs_path} {target_parent_dir}\"\n","        subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n","        print(\"  Dataset downloaded successfully.\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\" Error downloading dataset: {e.stderr}\")\n","        exit()\n","\n","download_dataset_from_gcs(GCS_BUCKET_NAME, GCS_DATASET_PATH, LOCAL_DATA_ROOT)\n","\n","\n","# ---- 4. CNN ARCHITECTURE (STABLE VERSION) ----\n","class CNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN, self).__init__()\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(3, 16, 3, 1, 1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(16, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block3 = nn.Sequential(\n","            nn.Conv2d(64, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block4 = nn.Sequential(\n","            nn.Conv2d(256, 1024, 3, 1, 1), nn.BatchNorm2d(1024), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(1024, 512)\n","        self.fc2 = nn.Linear(512, 128)\n","        self.fc_out = nn.Linear(128, num_classes)\n","        self.dropout = nn.Dropout(0.12)\n","\n","    def forward(self, x):\n","        x = self.conv_block1(x)\n","        x = self.conv_block2(x)\n","        x = self.conv_block3(x)\n","        x = self.conv_block4(x)\n","        x = self.pool(x)\n","        x = self.flatten(x)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.fc2(x))\n","        return self.fc_out(x)\n","\n","\n","# ---- 5. DEVICE ----\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\" Using device: {DEVICE}\")\n","\n","# ---- 6. DATA ----\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(CONFIG[\"image_size\"], scale=(0.8, 1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(CONFIG[\"image_size\"]),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_data = datasets.ImageFolder(os.path.join(LOCAL_DATA_ROOT, \"train\"), transform=train_transform)\n","val_data = datasets.ImageFolder(os.path.join(LOCAL_DATA_ROOT, \"val\"), transform=val_transform)\n","\n","train_loader = DataLoader(train_data, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_data, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=2, pin_memory=True)\n","\n","# ---- 7. MODEL/LOSS/OPTIMIZER ----\n","model = CNN(num_classes=len(train_data.classes)).to(DEVICE)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=CONFIG[\"min_lr\"])\n","\n","# ---- 8. TRAINING LOOP ----\n","train_losses, val_losses, train_accs, val_accs, epoch_times = [], [], [], [], []\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","patience = 5\n","\n","print(\" Starting training...\\n\")\n","total_start_time = time.time()\n","\n","for epoch in range(CONFIG[\"num_epochs\"]):\n","    epoch_start = time.time()\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","\n","    for batch_idx, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","        if (batch_idx + 1) % max(1, len(train_loader)//5) == 0:\n","            print(f\" Epoch [{epoch+1}/{CONFIG['num_epochs']}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n","\n","    avg_train_loss = running_loss / total\n","    train_acc = 100 * correct / total\n","\n","    # Validation\n","    model.eval()\n","    val_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            val_correct += (preds == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    avg_val_loss = val_loss / val_total\n","    val_acc = 100 * val_correct / val_total\n","\n","    train_losses.append(avg_train_loss)\n","    val_losses.append(avg_val_loss)\n","    train_accs.append(train_acc)\n","    val_accs.append(val_acc)\n","\n","    scheduler.step(avg_val_loss)\n","    epoch_time = time.time() - epoch_start\n","    epoch_times.append(epoch_time)\n","\n","    improved = avg_val_loss < best_val_loss\n","    if improved:\n","        best_val_loss = avg_val_loss\n","        epochs_no_improve = 0\n","        torch.save(model.state_dict(), CONFIG[\"best_model_path\"])\n","    else:\n","        epochs_no_improve += 1\n","\n","    print(f\"\\n Epoch [{epoch+1}/{CONFIG['num_epochs']}] Summary:\")\n","    print(f\"   Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n","    print(f\"   Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}% {'*IMPROVED*' if improved else ''}\")\n","    print(f\"   Patience: {epochs_no_improve}/{patience}\")\n","\n","    if epochs_no_improve >= patience:\n","        print(f\"\\nEarly stopping triggered after {patience} epochs with no improvement. Loading best model.\")\n","        model.load_state_dict(torch.load(CONFIG[\"best_model_path\"]))\n","        break\n","\n","# ---- 9. SAVE METRICS ----\n","metrics = {\n","    \"train_loss\": train_losses,\n","    \"val_loss\": val_losses,\n","    \"train_acc\": train_accs,\n","    \"val_acc\": val_accs,\n","    \"epoch_times\": epoch_times,\n","    \"best_val_loss\": best_val_loss,\n","}\n","with open(CONFIG[\"metrics_json\"], \"w\") as f:\n","    json.dump(metrics, f, indent=4)\n","\n","print(f\"\\nMetrics saved to {CONFIG['metrics_json']}\")\n","\n","# ---- 10. PLOT CURVES ----\n","plt.style.use('seaborn-v0_8-darkgrid')\n","plt.figure(figsize=(12,5))\n","plt.subplot(1,2,1)\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Val Loss')\n","plt.legend()\n","plt.title('Loss Curve')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","\n","plt.subplot(1,2,2)\n","plt.plot(train_accs, label='Train Acc')\n","plt.plot(val_accs, label='Val Acc')\n","plt.legend()\n","plt.title('Accuracy Curve')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","\n","plt.tight_layout()\n","plt.savefig(os.path.join(RUN_METRICS_DIR, \"training_curves.png\"))\n","plt.show()\n","\n","# ---- 11. CONFUSION MATRIX & REPORT ----\n","all_preds, all_labels = [], []\n","model.eval()\n","with torch.no_grad():\n","    for inputs, labels in val_loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","cm = confusion_matrix(all_labels, all_preds)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_data.classes)\n","fig, ax = plt.subplots(figsize=(10, 10))\n","disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation=45)\n","plt.title(\"Confusion Matrix\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(RUN_METRICS_DIR, \"confusion_matrix.png\"))\n","plt.show()\n","\n","report = classification_report(all_labels, all_preds, target_names=train_data.classes, zero_division=0)\n","with open(os.path.join(RUN_METRICS_DIR, \"classification_report.txt\"), \"w\") as f:\n","    f.write(report)\n","print(\"\\nClassification Report:\")\n","print(report)\n","\n","print(\"\\nTraining complete! All metrics & plots saved.\")"],"metadata":{"id":"lcLRBxw-xl3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========================================\n","#   Feature Extraction (CustomCNN v2 Only)\n","# ========================================\n","\n","import os\n","import torch\n","import pickle\n","from torch import nn\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import numpy as np\n","\n","# -------- Configuration --------\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","BATCH_SIZE = 64\n","IMAGE_SIZE = (224, 224)\n","NUM_CLASSES = 20\n","DATASET_PATH = \"/content/cnn_set\"\n","FEATURE_SAVE_DIR = \"/content/drive/MyDrive/ImageRetrievalProject/features\"\n","os.makedirs(FEATURE_SAVE_DIR, exist_ok=True)\n","print(f\"Using device: {DEVICE}\")\n","\n","# -------- Model Weights Paths (MODIFIED) --------\n","# Only contains the customcnn model and specifies a unique output name\n","WEIGHTS = {\n","    \"customcnn\": {\n","        \"path\": \"/content/drive/MyDrive/ImageRetrievalProject/metrics/customcnn_v2_50epoch/best_model.pth\",\n","        \"output_filename\": \"customcnn_v2_features.pkl\"\n","    }\n","}\n","\n","# -------- Image Transforms --------\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(IMAGE_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# -------- Custom Dataset to include image paths --------\n","class ImagePathDataset(datasets.ImageFolder):\n","    def __getitem__(self, index):\n","        path, target = self.samples[index]\n","        img = self.loader(path)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, self.targets[index], path\n","\n","# -------- Datasets & Dataloaders --------\n","full_dataset = ImagePathDataset(DATASET_PATH, transform=transform)\n","full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n","print(f\"Found {len(full_dataset)} images in {DATASET_PATH}\")\n","\n","\n","# ========================================\n","#   1. STABLE Custom CNN Definition\n","# ========================================\n","class CustomCNN(nn.Module):\n","    def __init__(self, num_classes=NUM_CLASSES):\n","        super(CustomCNN, self).__init__()\n","        self.conv_block1 = nn.Sequential(\n","            nn.Conv2d(3, 16, 3, 1, 1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block2 = nn.Sequential(\n","            nn.Conv2d(16, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block3 = nn.Sequential(\n","            nn.Conv2d(64, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_block4 = nn.Sequential(\n","            nn.Conv2d(256, 1024, 3, 1, 1), nn.BatchNorm2d(1024), nn.ReLU(), nn.MaxPool2d(2, 2)\n","        )\n","        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(1024, 512)\n","        self.fc2 = nn.Linear(512, 128)\n","        self.fc_out = nn.Linear(128, num_classes)\n","        self.dropout = nn.Dropout(0.15)\n","\n","    def forward(self, x):\n","        x = self.conv_block1(x); x = self.conv_block2(x); x = self.conv_block3(x); x = self.conv_block4(x)\n","        x = self.pool(x); x = self.flatten(x)\n","        x = F.relu(self.fc1(x)); x = self.dropout(x); x = F.relu(self.fc2(x))\n","        return self.fc_out(x)\n","\n","\n","# ========================================\n","#   2. Unified Feature Extractor Class\n","# ========================================\n","class FeatureExtractor(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        self.model_name = model_name\n","\n","        full_model = self._load_full_model(model_name)\n","\n","        # MODIFIED: Get weight path from nested dictionary\n","        weight_path = WEIGHTS.get(model_name, {}).get(\"path\")\n","        if weight_path and os.path.exists(weight_path):\n","            try:\n","                full_model.load_state_dict(torch.load(weight_path, map_location=DEVICE))\n","                print(f\"Successfully loaded weights for {model_name} from {weight_path}\")\n","            except Exception as e:\n","                print(f\"Error loading weights for {model_name}: {e}.\")\n","        else:\n","            print(f\"Warning: Weights not found for {model_name}.\")\n","\n","        self.feature_model = self._create_feature_model(full_model).to(DEVICE).eval()\n","\n","    def _load_full_model(self, name):\n","        if name == \"customcnn\":\n","            return CustomCNN(num_classes=NUM_CLASSES)\n","        # Other model definitions are not needed since we only run customcnn\n","        else:\n","            raise ValueError(f\"Unknown model name: {name}\")\n","\n","    def _create_feature_model(self, full_model):\n","        if self.model_name == \"customcnn\":\n","            return nn.Sequential(\n","                full_model.conv_block1, full_model.conv_block2, full_model.conv_block3, full_model.conv_block4,\n","                full_model.pool, full_model.flatten,\n","                full_model.fc1, nn.ReLU(), full_model.dropout, full_model.fc2\n","            )\n","\n","    def forward(self, x):\n","        with torch.no_grad():\n","            features = self.feature_model(x.to(DEVICE))\n","            return features.cpu().numpy()\n","\n","\n","# ========================================\n","#   3. Main Execution Loop\n","# ========================================\n","def main():\n","\n","    for model_name in WEIGHTS.keys():\n","        print(f\"\\n--- Processing model: {model_name.upper()} ---\")\n","\n","        extractor = FeatureExtractor(model_name)\n","\n","        all_features, all_labels, all_paths = [], [], []\n","        for inputs, labels, paths in tqdm(full_loader, desc=f\"Extracting {model_name} features\"):\n","            batch_features = extractor(inputs)\n","            all_features.append(batch_features)\n","            all_labels.extend(labels.numpy())\n","            all_paths.extend(paths)\n","\n","        all_features = np.vstack(all_features)\n","\n","\n","        output_filename = WEIGHTS[model_name].get(\"output_filename\", f\"{model_name}_features.pkl\")\n","        save_path = os.path.join(FEATURE_SAVE_DIR, output_filename)\n","\n","        with open(save_path, 'wb') as f:\n","            pickle.dump({\n","                'features': all_features,\n","                'labels': all_labels,\n","                'paths': all_paths\n","            }, f)\n","        print(f\" Saved {len(all_features)} features for {model_name} to {save_path}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"kXmlo3-_VH2f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================\n","# TRAINING SCRIPT PRETRAINED MODELS\n","# ==================================\n","import os\n","import time\n","import json\n","import subprocess\n","from pathlib import Path\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","\n","# -----------------------\n","# User Config\n","# -----------------------\n","MODEL_NAME = \"resnet50\"       # choose model to be train: \"resnet50\", \"efficientnet_b0\", \"vgg16\"\n","NUM_EPOCHS = 30\n","BATCH_SIZE = 64\n","LEARNING_RATE = 1e-5\n","WEIGHT_DECAY = 1e-4\n","MIN_LR = 1e-7\n","PATIENCE = 4\n","IMAGE_SIZE = (224, 224)\n","\n","# GCS dataset info (will download if LOCAL_DATA_ROOT missing)\n","GCS_BUCKET_NAME = \"similar_dataset\"\n","GCS_DATASET_PATH = \"cnn_set\"\n","LOCAL_DATA_ROOT = \"/content/cnn_set\"\n","\n","DRIVE_CANDIDATE = Path(\"/content/drive/MyDrive\")\n","\n","# -----------------------\n","# 1) Mount Google Drive (safe) and set DRIVE_ROOT\n","# -----------------------\n","try:\n","    # only works in Colab\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    print(\" Google Drive mount requested.\")\n","except Exception as e:\n","    print(\"google.colab.drive not available or mount popup skipped:\", e)\n","\n","if DRIVE_CANDIDATE.exists():\n","    DRIVE_ROOT = DRIVE_CANDIDATE\n","    print(\"Google Drive available:\", DRIVE_ROOT)\n","else:\n","    DRIVE_ROOT = Path(\"/content\")\n","    print(\" Google Drive not found; using local path\", DRIVE_ROOT)\n","\n","# -----------------------\n","# 2) Download dataset from GCS if missing\n","# -----------------------\n","def download_dataset_from_gcs(bucket_name, gcs_path, local_path):\n","    if os.path.exists(local_path):\n","        print(f\"Dataset already exists at {local_path}, skipping GCS download.\")\n","        return\n","    print(f\" Downloading dataset from gs://{bucket_name}/{gcs_path} to /content/ ...\")\n","    cmd = f\"gsutil -m cp -r gs://{bucket_name}/{gcs_path} /content/\"\n","    try:\n","        subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)\n","        # The GCS copy will create /content/{gcs_path} or /content/cnn_set\n","        if os.path.exists(local_path):\n","            print(\"Dataset downloaded to\", local_path)\n","        else:\n","            print(\"Download finished but expected path not found:\", local_path)\n","    except subprocess.CalledProcessError as e:\n","        print(\"Error downloading dataset from GCS. stderr:\")\n","        print(e.stderr)\n","        print(\"Make sure you have 'gsutil' available and the bucket is public/your account has access.\")\n","        raise\n","\n","\n","try:\n","    download_dataset_from_gcs(GCS_BUCKET_NAME, GCS_DATASET_PATH, LOCAL_DATA_ROOT)\n","except Exception:\n","    print(\"Proceeding — if dataset is not present locally, script will fail when loading data.\")\n","\n","# -----------------------\n","# 3) Verify dataset layout\n","# -----------------------\n","train_dir = os.path.join(LOCAL_DATA_ROOT, \"train\")\n","val_dir = os.path.join(LOCAL_DATA_ROOT, \"val\")\n","if not (os.path.isdir(train_dir) and os.path.isdir(val_dir)):\n","    raise FileNotFoundError(f\"Expected dataset at {train_dir} and {val_dir}. Please ensure dataset exists or GCS download succeeded.\")\n","\n","# -----------------------\n","# 4) Transforms & Dataloaders\n","# -----------------------\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8,1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(IMAGE_SIZE),\n","    transforms.CenterCrop(IMAGE_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n","])\n","\n","train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n","val_dataset = datasets.ImageFolder(val_dir, transform=val_transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n","\n","num_classes = len(train_dataset.classes)\n","print(f\"Found {num_classes} classes. Example classes: {train_dataset.classes[:8]}\")\n","\n","# -----------------------\n","# 5) Model factory (replace head)\n","# -----------------------\n","def get_model(name, num_classes, device):\n","    name = name.lower()\n","    if name == \"resnet50\":\n","        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n","        model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    elif name in (\"efficientnet_b0\", \"efficientnetb0\", \"efficientnet-b0\"):\n","        # handle different torchvision versions: classifier may be Sequential or Linear\n","        try:\n","            model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n","        except AttributeError:\n","            # older torchvision may not have weights enum; try without enum\n","            model = models.efficientnet_b0(pretrained=True)\n","        # replace classifier last linear\n","        if hasattr(model, \"classifier\"):\n","            # common pattern: Sequential(Dropout, Linear)\n","            cl = model.classifier\n","            if isinstance(cl, nn.Sequential) and isinstance(cl[-1], nn.Linear):\n","                in_f = cl[-1].in_features\n","                cl[-1] = nn.Linear(in_f, num_classes)\n","                model.classifier = cl\n","            elif isinstance(cl, nn.Linear):\n","                model.classifier = nn.Linear(cl.in_features, num_classes)\n","            else:\n","                raise RuntimeError(\"Unexpected EfficientNet classifier structure.\")\n","        else:\n","            raise RuntimeError(\"EfficientNet model missing 'classifier' attribute.\")\n","    elif name in (\"vgg16\", \"vgg_16\"):\n","        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n","        # classifier is Sequential; last element usually Linear\n","        if isinstance(model.classifier, nn.Sequential) and isinstance(model.classifier[-1], nn.Linear):\n","            in_f = model.classifier[-1].in_features\n","            model.classifier[-1] = nn.Linear(in_f, num_classes)\n","        else:\n","            raise RuntimeError(\"Unexpected VGG classifier structure.\")\n","    else:\n","        raise ValueError(\"Unknown model name: \" + name)\n","    return model.to(device)\n","\n","# -----------------------\n","# 6) Device and instantiate model\n","# -----------------------\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", DEVICE)\n","model = get_model(MODEL_NAME, num_classes, DEVICE)\n","print(\"Model created:\", MODEL_NAME)\n","\n","# -----------------------\n","# 7) Output directories & model summary\n","# -----------------------\n","RUN_METRICS_DIR = Path(DRIVE_ROOT) / \"metrics\" / f\"{MODEL_NAME}_{NUM_EPOCHS}epoch\"\n","RUN_METRICS_DIR.mkdir(parents=True, exist_ok=True)\n","BEST_MODEL_PATH = RUN_METRICS_DIR / \"best_model.pth\"\n","FINAL_MODEL_PATH = RUN_METRICS_DIR / f\"{MODEL_NAME}_final.pth\"\n","METRICS_JSON = RUN_METRICS_DIR / \"metrics.json\"\n","MODEL_SUMMARY_PATH = RUN_METRICS_DIR / \"model_summary.txt\"\n","\n","with open(MODEL_SUMMARY_PATH, \"w\") as f:\n","    f.write(str(model))\n","print(\"Saving outputs to:\", RUN_METRICS_DIR)\n","\n","# -----------------------\n","# 8) Optimizer / Loss / Scheduler\n","# -----------------------\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=PATIENCE, min_lr=MIN_LR)\n","\n","# -----------------------\n","# 9) Training loop\n","# -----------------------\n","train_losses, val_losses = [], []\n","train_accs, val_accs = [], []\n","epoch_times = []\n","best_val_loss = float(\"inf\")\n","best_epoch = None\n","epochs_no_improve = 0\n","\n","print_interval = max(1, len(train_loader) // 10)  # ~10 prints per epoch\n","\n","print(\"Starting training...\")\n","\n","total_start = time.time()\n","for epoch in range(NUM_EPOCHS):\n","    epoch_start = time.time()\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (inputs, labels) in enumerate(train_loader):\n","        inputs = inputs.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        preds = outputs.argmax(dim=1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","        if (batch_idx + 1) % print_interval == 0 or (batch_idx + 1) == len(train_loader):\n","            print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n","\n","    avg_train_loss = running_loss / total if total > 0 else 0.0\n","    train_acc = 100.0 * correct / total if total > 0 else 0.0\n","\n","    # Validation\n","    model.eval()\n","    running_val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    all_val_preds, all_val_labels = [], []\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs = inputs.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            running_val_loss += loss.item() * inputs.size(0)\n","            preds = outputs.argmax(dim=1)\n","            val_correct += (preds == labels).sum().item()\n","            val_total += labels.size(0)\n","            all_val_preds.extend(preds.cpu().numpy())\n","            all_val_labels.extend(labels.cpu().numpy())\n","\n","    avg_val_loss = running_val_loss / val_total if val_total > 0 else float('inf')\n","    val_acc = 100.0 * val_correct / val_total if val_total > 0 else 0.0\n","\n","    train_losses.append(float(avg_train_loss))\n","    val_losses.append(float(avg_val_loss))\n","    train_accs.append(float(train_acc))\n","    val_accs.append(float(val_acc))\n","\n","    # Scheduler step and LR logging\n","    prev_lr = optimizer.param_groups[0]['lr']\n","    scheduler.step(avg_val_loss)\n","    curr_lr = optimizer.param_groups[0]['lr']\n","    if curr_lr < prev_lr:\n","        print(f\"Learning rate reduced from {prev_lr:.8f} to {curr_lr:.8f}\")\n","\n","    epoch_time = time.time() - epoch_start\n","    epoch_times.append(epoch_time)\n","    avg_epoch_time = float(np.mean(epoch_times))\n","    remaining_epochs = NUM_EPOCHS - (epoch + 1)\n","    eta_seconds = int(remaining_epochs * avg_epoch_time)\n","\n","    improved = avg_val_loss < best_val_loss\n","    if improved:\n","        best_val_loss = float(avg_val_loss)\n","        best_epoch = epoch + 1\n","        epochs_no_improve = 0\n","        torch.save(model.state_dict(), BEST_MODEL_PATH)\n","    else:\n","        epochs_no_improve += 1\n","\n","    improvement_str = \"  New best model saved!\" if improved else \"\"\n","    print(f\"\\nEpoch [{epoch+1}/{NUM_EPOCHS}] Summary:\")\n","    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n","    print(f\"  Val   Loss: {avg_val_loss:.4f} | Val   Acc: {val_acc:.2f}%{improvement_str}\")\n","    print(f\"  Epoch Time: {epoch_time:.2f}s | ETA: ~{eta_seconds//60}m {eta_seconds%60}s\")\n","    print(f\"  Patience Counter: {epochs_no_improve}/{PATIENCE}\\n\")\n","\n","    # early stopping prompt\n","    if epochs_no_improve >= PATIENCE:\n","        choice = input(f\" Validation loss hasn't improved for {PATIENCE} epochs. Type 'stop' to end training or press Enter to continue: \")\n","        if choice.lower() == 'stop':\n","            print(\"Early stopping chosen. Restoring best model and stopping training.\")\n","            if BEST_MODEL_PATH.exists():\n","                model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n","            break\n","        else:\n","            print(\"Continuing training (you pressed Enter). Patience counter reset.\")\n","            epochs_no_improve = 0\n","\n","# end training\n","total_time = time.time() - total_start\n","print(f\"Training finished in {total_time/60:.2f} minutes. Best epoch: {best_epoch}, best_val_loss: {best_val_loss:.6f}\")\n","\n","# ensure best weights loaded\n","if BEST_MODEL_PATH.exists():\n","    try:\n","        model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n","        print(f\"Loaded best model from epoch {best_epoch}.\")\n","    except Exception as e:\n","        print(\"Warning: could not load best checkpoint:\", e)\n","\n","# save final model\n","torch.save(model.state_dict(), FINAL_MODEL_PATH)\n","print(\"Saved final model to:\", FINAL_MODEL_PATH)\n","\n","# -----------------------\n","# 10) Final evaluation & save metrics/plots\n","# -----------------------\n","model.eval()\n","all_preds, all_labels = [], []\n","with torch.no_grad():\n","    for inputs, labels in val_loader:\n","        inputs = inputs.to(DEVICE); labels = labels.to(DEVICE)\n","        outputs = model(inputs)\n","        preds = outputs.argmax(dim=1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# confusion matrix + classification report\n","if len(all_labels) > 0:\n","    cm = confusion_matrix(all_labels, all_preds)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)\n","    disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n","    cm_path = RUN_METRICS_DIR / \"confusion_matrix.png\"\n","    plt.title(\"Confusion Matrix\")\n","    plt.savefig(cm_path, bbox_inches='tight')\n","    plt.show()\n","    print(\"Saved confusion matrix to:\", cm_path)\n","\n","    report = classification_report(all_labels, all_preds, target_names=train_dataset.classes, digits=4)\n","    report_path = RUN_METRICS_DIR / \"classification_report.txt\"\n","    with open(report_path, \"w\") as f:\n","        f.write(report)\n","    print(\"Saved classification report to:\", report_path)\n","    print(\"\\nClassification report:\\n\", report)\n","else:\n","    print(\"No validation labels found; skipping confusion matrix and report.\")\n","\n","# save loss/accuracy curves\n","epochs_range = range(1, len(train_losses) + 1)\n","plt.figure(figsize=(12,5))\n","plt.subplot(1,2,1)\n","plt.plot(epochs_range, train_losses, label='Train Loss')\n","plt.plot(epochs_range, val_losses, label='Val Loss')\n","plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curve\"); plt.legend()\n","plt.subplot(1,2,2)\n","plt.plot(epochs_range, train_accs, label='Train Acc')\n","plt.plot(epochs_range, val_accs, label='Val Acc')\n","plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy (%)\"); plt.title(\"Accuracy Curve\"); plt.legend()\n","lossacc_path = RUN_METRICS_DIR / \"training_curves.png\"\n","plt.savefig(lossacc_path, bbox_inches='tight')\n","plt.show()\n","print(\"Saved training curves to:\", lossacc_path)\n","\n","# save epoch times and metrics json\n","epoch_times_path = RUN_METRICS_DIR / \"epoch_times.npy\"\n","np.save(epoch_times_path, np.array(epoch_times))\n","print(\"Saved epoch times to:\", epoch_times_path)\n","\n","metrics = {\n","    \"train_losses\": train_losses,\n","    \"val_losses\": val_losses,\n","    \"train_accuracies\": train_accs,\n","    \"val_accuracies\": val_accs,\n","    \"epoch_times\": epoch_times,\n","    \"best_val_loss\": float(best_val_loss),\n","    \"best_epoch\": best_epoch,\n","    \"model_name\": MODEL_NAME,\n","    \"num_epochs_run\": len(train_losses),\n","    \"class_labels\": train_dataset.classes\n","}\n","with open(METRICS_JSON, \"w\") as f:\n","    json.dump(metrics, f, indent=2)\n","print(\"Saved metrics JSON to:\", METRICS_JSON)\n","\n","print(\"All done. Files saved in:\", RUN_METRICS_DIR)\n"],"metadata":{"id":"ftCA1rjmU6sZ"},"execution_count":null,"outputs":[]}]}